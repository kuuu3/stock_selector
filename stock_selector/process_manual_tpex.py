#!/usr/bin/env python3
"""
æ«ƒè²·ä¸­å¿ƒæ‰‹å‹•ä¸‹è¼‰æ•¸æ“šè™•ç†è…³æœ¬

ä½¿ç”¨æ–¹å¼ï¼š
1. å‰å¾€æ«ƒè²·ä¸­å¿ƒå€‹è‚¡æ—¥æˆäº¤è³‡è¨Šé é¢ï¼š
   https://www.tpex.org.tw/zh-tw/mainboard/trading/info/stock-pricing.html

2. ä¸‹è¼‰æ‰€éœ€è‚¡ç¥¨çš„æ­·å²æ•¸æ“šï¼š
   - è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¦‚ï¼š3260, 3324, 5443ï¼‰
   - é¸æ“‡è³‡æ–™å¹´æœˆç¯„åœï¼ˆå»ºè­°é¸æ“‡éå» 1-3 å€‹æœˆï¼‰
   - é»æ“Šã€Œä¸‹è¼‰CSVæª”(UTF-8)ã€

3. å°‡ä¸‹è¼‰çš„ CSV æª”æ¡ˆæ”¾å…¥ data/manual_tpex/ è³‡æ–™å¤¾

4. é‹è¡Œæ­¤è…³æœ¬è™•ç†æ•¸æ“šï¼š
   python process_manual_tpex.py

5. è™•ç†å¾Œçš„æ•¸æ“šå°‡æ•´åˆåˆ°ä¸»æ•¸æ“šåº«ä¸­
"""

import sys
import logging
from pathlib import Path

# æ·»åŠ  src åˆ° Python è·¯å¾‘
sys.path.insert(0, 'src')

from src.data_collection.tpex_manual_loader import TPEXManualLoader
from src.config import get_data_file_path
import pandas as pd

def main():
    """ä¸»å‡½æ•¸"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    print("=" * 60)
    print("æ«ƒè²·ä¸­å¿ƒæ‰‹å‹•ä¸‹è¼‰æ•¸æ“šè™•ç†å·¥å…·")
    print("=" * 60)
    
    # åˆå§‹åŒ–è™•ç†å™¨
    loader = TPEXManualLoader()
    
    # æª¢æŸ¥å¯ç”¨æª”æ¡ˆ
    available_files = loader.get_available_files()
    
    if not available_files:
        print("\nâŒ æ²’æœ‰æ‰¾åˆ°æ‰‹å‹•ä¸‹è¼‰çš„ CSV æª”æ¡ˆ")
        print("\nğŸ“‹ ä½¿ç”¨èªªæ˜ï¼š")
        print("1. å‰å¾€æ«ƒè²·ä¸­å¿ƒå€‹è‚¡æ—¥æˆäº¤è³‡è¨Šé é¢ï¼š")
        print("   https://www.tpex.org.tw/zh-tw/mainboard/trading/info/stock-pricing.html")
        print("\n2. ä¸‹è¼‰æ‰€éœ€è‚¡ç¥¨çš„æ­·å²æ•¸æ“šï¼š")
        print("   - è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¦‚ï¼š3260, 3324, 5443ï¼‰")
        print("   - é¸æ“‡è³‡æ–™å¹´æœˆç¯„åœï¼ˆå»ºè­°é¸æ“‡éå» 1-3 å€‹æœˆï¼‰")
        print("   - é»æ“Šã€Œä¸‹è¼‰CSVæª”(UTF-8)ã€")
        print("\n3. å°‡ä¸‹è¼‰çš„ CSV æª”æ¡ˆæ”¾å…¥ data/manual_tpex/ è³‡æ–™å¤¾")
        print("\n4. é‡æ–°é‹è¡Œæ­¤è…³æœ¬ï¼š")
        print("   python process_manual_tpex.py")
        return
    
    print(f"\nâœ… æ‰¾åˆ° {len(available_files)} å€‹ CSV æª”æ¡ˆï¼š")
    for i, file in enumerate(available_files, 1):
        print(f"   {i}. {file}")
    
    # è™•ç†æ‰€æœ‰æª”æ¡ˆ
    print(f"\nğŸ”„ é–‹å§‹è™•ç† {len(available_files)} å€‹æª”æ¡ˆ...")
    combined_df = loader.process_all_manual_files()
    
    if combined_df.empty:
        print("âŒ æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½•æ•¸æ“š")
        return
    
    print(f"\nâœ… æˆåŠŸè™•ç† {len(combined_df)} ç­†æ•¸æ“š")
    
    # é¡¯ç¤ºè™•ç†çµæœ
    print(f"\nğŸ“Š æ•¸æ“šçµ±è¨ˆï¼š")
    print(f"   ç¸½ç­†æ•¸ï¼š{len(combined_df)}")
    print(f"   è‚¡ç¥¨æ•¸é‡ï¼š{len(combined_df['stock_code'].unique())}")
    # éæ¿¾æ‰ NaN æ—¥æœŸ
    valid_dates = combined_df['date'].dropna()
    if not valid_dates.empty:
        print(f"   æ—¥æœŸç¯„åœï¼š{valid_dates.min()} åˆ° {valid_dates.max()}")
    else:
        print("   æ—¥æœŸç¯„åœï¼šç„¡æœ‰æ•ˆæ—¥æœŸ")
    
    print(f"\nğŸ“ˆ å„è‚¡ç¥¨æ•¸æ“šï¼š")
    for stock_code in sorted(combined_df['stock_code'].unique()):
        stock_data = combined_df[combined_df['stock_code'] == stock_code]
        print(f"   è‚¡ç¥¨ {stock_code}ï¼š{len(stock_data)} ç­†æ•¸æ“š")
        if len(stock_data) > 0:
            date_range = f"{stock_data['date'].min()} åˆ° {stock_data['date'].max()}"
            print(f"     æ—¥æœŸç¯„åœï¼š{date_range}")
    
    # ä¿å­˜è™•ç†å¾Œçš„æ•¸æ“š
    output_file = "data/processed/tpex_historical.csv"
    loader.save_processed_data(combined_df, output_file)
    
    # æ•´åˆåˆ°ä¸»æ•¸æ“šåº«
    print(f"\nğŸ”„ æ•´åˆåˆ°ä¸»æ•¸æ“šåº«...")
    integrate_with_main_database(combined_df)
    
    print(f"\nğŸ‰ è™•ç†å®Œæˆï¼")
    print(f"   è™•ç†å¾Œçš„æ•¸æ“šå·²ä¿å­˜åˆ°ï¼š{output_file}")
    print(f"   å·²æ•´åˆåˆ°ä¸»æ•¸æ“šåº«ï¼šdata/raw/prices.csv")

def integrate_with_main_database(tpex_df: pd.DataFrame):
    """
    å°‡ TPEX æ­·å²æ•¸æ“šæ•´åˆåˆ°ä¸»æ•¸æ“šåº«
    
    Args:
        tpex_df: TPEX æ­·å²æ•¸æ“š DataFrame
    """
    try:
        # è¼‰å…¥ç¾æœ‰æ•¸æ“š
        price_path = get_data_file_path('raw/prices.csv')
        
        if price_path.exists():
            existing_df = pd.read_csv(price_path)
            print(f"   ç¾æœ‰æ•¸æ“šï¼š{len(existing_df)} ç­†")
            
            # åˆä½µæ•¸æ“š
            combined_df = pd.concat([existing_df, tpex_df], ignore_index=True)
            
            # å»é‡ï¼ˆä¿ç•™æœ€æ–°çš„æ•¸æ“šï¼‰
            combined_df = combined_df.drop_duplicates(
                subset=['stock_code', 'date'], 
                keep='last'
            ).sort_values(['stock_code', 'date'])
            
            # ä¿å­˜åˆä½µå¾Œçš„æ•¸æ“š
            combined_df.to_csv(price_path, index=False)
            
            print(f"   æ•´åˆå¾Œæ•¸æ“šï¼š{len(combined_df)} ç­†")
            print(f"   æ–°å¢æ•¸æ“šï¼š{len(combined_df) - len(existing_df)} ç­†")
            
        else:
            # å¦‚æœæ²’æœ‰ç¾æœ‰æ•¸æ“šï¼Œç›´æ¥ä¿å­˜ TPEX æ•¸æ“š
            tpex_df.to_csv(price_path, index=False)
            print(f"   å‰µå»ºæ–°çš„ä¸»æ•¸æ“šåº«ï¼š{len(tpex_df)} ç­†æ•¸æ“š")
            
    except Exception as e:
        print(f"âŒ æ•´åˆåˆ°ä¸»æ•¸æ“šåº«å¤±æ•—ï¼š{e}")
        raise

if __name__ == "__main__":
    main()
